{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'track_id', 'date_gmt', 'latitude_mean', 'longitude_mean',\n",
       "       'lat_colony_mean', 'lon_colony_mean', 'km_to_colony_mean',\n",
       "       'km_since_last_measure_mean', 'delta_km_north_mean',\n",
       "       'delta_km_south_mean', 'delta_km_east_mean', 'delta_km_west_mean',\n",
       "       'minutes_since_last_measure_mean', 'latitude_std', 'longitude_std',\n",
       "       'lat_colony_std', 'lon_colony_std', 'km_to_colony_std',\n",
       "       'km_since_last_measure_std', 'delta_km_north_std', 'delta_km_south_std',\n",
       "       'delta_km_east_std', 'delta_km_west_std',\n",
       "       'minutes_since_last_measure_std', 'latitude_min', 'longitude_min',\n",
       "       'lat_colony_min', 'lon_colony_min', 'km_to_colony_min',\n",
       "       'km_since_last_measure_min', 'delta_km_north_min', 'delta_km_south_min',\n",
       "       'delta_km_east_min', 'delta_km_west_min',\n",
       "       'minutes_since_last_measure_min', 'latitude_max', 'longitude_max',\n",
       "       'lat_colony_max', 'lon_colony_max', 'km_to_colony_max',\n",
       "       'km_since_last_measure_max', 'delta_km_north_max', 'delta_km_south_max',\n",
       "       'delta_km_east_max', 'delta_km_west_max',\n",
       "       'minutes_since_last_measure_max', 'common_name', 'site_name',\n",
       "       'colony_name', 't2m', 'tp', 'sst', 'siconc', 'sd', 'rsn', 'avg_smr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PENGUIN_DATASET = '/Users/philipp/Documents/02_Master_Uni/Uni_TuÌˆbingen/Semester_1/06 Data Literacy/02 Project/penguins_final_with_era5.csv'\n",
    "penguin_df = pd.read_csv(PENGUIN_DATASET)\n",
    "\n",
    "penguin_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'specie': 'Adelie Penguin', 'colonies': ['Admiralty Bay']}, {'specie': 'Chinstrap Penguin', 'colonies': ['Admiralty Bay', 'Cape Shirreff']}, {'specie': 'Gentoo Penguin', 'colonies': ['Admiralty Bay', 'Cape Shirreff']}]\n"
     ]
    }
   ],
   "source": [
    "# define used colonies:\n",
    "species = penguin_df['common_name'].unique()\n",
    "\n",
    "available_years = [str(x) for x in range(1996, 2018)]\n",
    "available_years = np.array(available_years)\n",
    "penguin_df['date_gmt'] = pd.to_datetime(penguin_df['date_gmt'])\n",
    "penguin_df['year'] = penguin_df['date_gmt'].dt.year.astype(str)\n",
    "sufficient_pairs = []\n",
    "\n",
    "for specie in species:\n",
    "    colonies_with_data = []\n",
    "    for colony in penguin_df[penguin_df['common_name'] == specie]['colony_name'].unique():\n",
    "        years_with_data = penguin_df[(penguin_df['common_name'] == specie) & (penguin_df['colony_name'] == colony)]['year'].unique()\n",
    "        if len(years_with_data) >= 8:\n",
    "            colonies_with_data.append(colony)\n",
    "    if colonies_with_data:\n",
    "        sufficient_pairs.append({'specie': specie, 'colonies': colonies_with_data})\n",
    "\n",
    "print(sufficient_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter df for adelie penguins and king george island\n",
    "df = penguin_df[(penguin_df['common_name'] == 'Adelie Penguin') & (penguin_df['colony_name'] == 'King George Island')]\n",
    "#df = penguin_df[(penguin_df['common_name'] == 'Adelie Penguin')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(df):\n",
    "    df = df.copy()\n",
    "    df['date_gmt'] = pd.to_datetime(df['date_gmt'])\n",
    "    df = df.sort_values(by='date_gmt')\n",
    "\n",
    "    # Feature Engineering\n",
    "    df['day_of_year'] = df['date_gmt'].dt.dayofyear\n",
    "    df['week_of_year'] = df['date_gmt'].dt.isocalendar().week\n",
    "    df['month'] = df['date_gmt'].dt.month\n",
    "    df['year'] = df['date_gmt'].dt.year\n",
    "\n",
    "    # Create lag features for 'tp' and 't2m'\n",
    "    for lag in range(1, 4):\n",
    "        df[f'tp_lag_{lag}'] = df['tp'].shift(lag)\n",
    "        df[f't2m_lag_{lag}'] = df['t2m'].shift(lag)\n",
    "\n",
    "    # Cyclical features for temporal variables\n",
    "    df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365.0)\n",
    "    df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365.0)\n",
    "    df['week_of_year_sin'] = np.sin(2 * np.pi * df['week_of_year'] / 52.0)\n",
    "    df['week_of_year_cos'] = np.cos(2 * np.pi * df['week_of_year'] / 52.0)\n",
    "\n",
    "    # Add lag features for additional variables\n",
    "    for lag in range(1, 4):\n",
    "        df[f'sst_lag_{lag}'] = df['sst'].shift(lag)\n",
    "        df[f'siconc_lag_{lag}'] = df['siconc'].shift(lag)\n",
    "        df[f'sd_lag_{lag}'] = df['sd'].shift(lag)\n",
    "        df[f'rsn_lag_{lag}'] = df['rsn'].shift(lag)\n",
    "        df[f'avg_smr_lag_{lag}'] = df['avg_smr'].shift(lag)\n",
    "\n",
    "    # # Rolling averages and cumulative sums for additional variables\n",
    "    # df['sst_rolling_7'] = df['sst'].rolling(window=7, min_periods=1).mean()\n",
    "    # df['siconc_rolling_7'] = df['siconc'].rolling(window=7, min_periods=1).mean()\n",
    "    # df['sd_cumsum'] = df['sd'].cumsum()\n",
    "    # df['rsn_cumsum'] = df['rsn'].cumsum()\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Define feature set and target variable\n",
    "    features = [\n",
    "        'tp', 't2m',  'sst', 'siconc', \n",
    "        'tp_lag_1', 'tp_lag_2', 'tp_lag_3',\n",
    "        't2m_lag_1', 't2m_lag_2', 't2m_lag_3', \n",
    "        'sst_lag_1', 'sst_lag_2', 'sst_lag_3', \n",
    "         'siconc_lag_1', 'siconc_lag_2', 'siconc_lag_3', \n",
    "        'year',\n",
    "        #  'week_of_year_sin', 'week_of_year_cos', \n",
    "        'day_of_year_sin', 'day_of_year_cos',\n",
    "        #   'sst_rolling_7', 'siconc_rolling_7', 'sd_cumsum', 'rsn_cumsum'\n",
    "    ]\n",
    "    target = 'km_to_colony_mean'\n",
    "    # target = 'km_since_last_measure_mean'\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "\n",
    "    # X100 = shap.utils.sample(X, 100) # 100 samples for use in Shapley value calculations\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = ['sst', 'siconc', 'tp', 't2m']\n",
    "    #X[scaled_features] = scaler.fit_transform(X[scaled_features])\n",
    "    #X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    return X, y, scaler, features, scaled_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_ridge_lasso(X, y):\n",
    "\n",
    "    # Ridge and Lasso models\n",
    "    ridge_model = Ridge(alpha=1.0)\n",
    "    lasso_model = Lasso(alpha=0.1)\n",
    "\n",
    "    # TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    # Lists to store evaluation metrics\n",
    "    ridge_r2_scores = []\n",
    "    ridge_rmse_scores = []\n",
    "    lasso_r2_scores = []\n",
    "    lasso_rmse_scores = []\n",
    "\n",
    "    # Model training and evaluation\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Ridge Regression\n",
    "        ridge_model.fit(X_train, y_train)\n",
    "        ridge_y_pred = ridge_model.predict(X_test)\n",
    "        ridge_r2_scores.append(r2_score(y_test, ridge_y_pred))\n",
    "        ridge_rmse_scores.append(np.sqrt(mean_squared_error(y_test, ridge_y_pred)))\n",
    "\n",
    "        # Lasso Regression\n",
    "        lasso_model.fit(X_train, y_train)\n",
    "        lasso_y_pred = lasso_model.predict(X_test)\n",
    "        lasso_r2_scores.append(r2_score(y_test, lasso_y_pred))\n",
    "        lasso_rmse_scores.append(np.sqrt(mean_squared_error(y_test, lasso_y_pred)))\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Ridge Average R^2 Score: {np.mean(ridge_r2_scores):.3f}\")\n",
    "    print(f\"Ridge Average RMSE: {np.mean(ridge_rmse_scores):.3f}\")\n",
    "    print(f\"Lasso Average R^2 Score: {np.mean(lasso_r2_scores):.3f}\")\n",
    "    print(f\"Lasso Average RMSE: {np.mean(lasso_rmse_scores):.3f}\")\n",
    "\n",
    "    # Save and print model coefficients\n",
    "    coefficients = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Ridge Coef': ridge_model.coef_,\n",
    "        'Lasso Coef': lasso_model.coef_\n",
    "    })\n",
    "    #print(coefficients)\n",
    "\n",
    "    coefficients['Ridge Importance'] = coefficients['Ridge Coef'].abs()\n",
    "    coefficients['Lasso Importance'] = coefficients['Lasso Coef'].abs()\n",
    "\n",
    "    # Sort by importance (descending order)\n",
    "    ridge_sorted = coefficients.sort_values(by='Ridge Importance', ascending=False)\n",
    "    lasso_sorted = coefficients.sort_values(by='Lasso Importance', ascending=False)\n",
    "\n",
    "    # Print sorted coefficients\n",
    "    #print(\"Ridge Coefficients Sorted by Importance:\")\n",
    "    #print(ridge_sorted[['Feature', 'Ridge Coef', 'Ridge Importance']])\n",
    "\n",
    "    print(\"\\nLasso Coefficients Sorted by Importance:\")\n",
    "    print(lasso_sorted[['Feature', 'Lasso Coef', 'Lasso Importance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_random_forest(X, y, features):\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=200,  # Number of trees\n",
    "        max_depth=20,      # Maximum depth of trees\n",
    "        random_state=42    # Reproducibility\n",
    "    )\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    # To store evaluation metrics\n",
    "    rf_r2_scores = []\n",
    "    rf_rmse_scores = []\n",
    "\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train Random Forest\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        rf_y_pred = rf_model.predict(X_test)\n",
    "        \n",
    "        # Evaluate Random Forest\n",
    "        rf_r2_scores.append(r2_score(y_test, rf_y_pred))\n",
    "        rf_rmse_scores.append(np.sqrt(mean_squared_error(y_test, rf_y_pred)))\n",
    "\n",
    "    # Print Random Forest results\n",
    "    print(f\"Random Forest Average R^2 Score: {np.mean(rf_r2_scores):.3f}\")\n",
    "    print(f\"Random Forest Average RMSE: {np.mean(rf_rmse_scores):.3f}\")\n",
    "\n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': rf_model.feature_importances_,\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_xgb(X, y):    \n",
    "    xgb_model = XGBRegressor(\n",
    "        n_estimators=100,  # Number of trees\n",
    "        max_depth=10,       # Maximum depth of each tree\n",
    "        learning_rate=0.05, # Learning rate\n",
    "        random_state=42    # Seed for reproducibility\n",
    "    )\n",
    "\n",
    "    # To store evaluation metrics\n",
    "    xgb_r2_scores = []\n",
    "    xgb_rmse_scores = []\n",
    "\n",
    "    # TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train XGBoost model\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = xgb_model.predict(X_test)\n",
    "        \n",
    "        # Evaluate model\n",
    "        xgb_r2_scores.append(r2_score(y_test, y_pred))\n",
    "        xgb_rmse_scores.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "    # Print XGBoost results\n",
    "    print(f\"XGBoost Average R^2 Score: {np.mean(xgb_r2_scores):.3f}\")\n",
    "    print(f\"XGBoost Average RMSE: {np.mean(xgb_rmse_scores):.3f}\")\n",
    "\n",
    "    xgb_feature_importance = xgb_model.feature_importances_\n",
    "\n",
    "    # Create a DataFrame for better visualization\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': xgb_feature_importance\n",
    "    })\n",
    "\n",
    "    # Sort by importance\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Print the feature importance\n",
    "    print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# penguins in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Average R^2 Score: 0.021\n",
      "Ridge Average RMSE: 369.674\n",
      "Lasso Average R^2 Score: 0.030\n",
      "Lasso Average RMSE: 368.300\n",
      "\n",
      "Lasso Coefficients Sorted by Importance:\n",
      "            Feature  Lasso Coef  Lasso Importance\n",
      "3            siconc  477.233899        477.233899\n",
      "0                tp -472.419000        472.419000\n",
      "18  day_of_year_cos -399.984381        399.984381\n",
      "17  day_of_year_sin  -77.572118         77.572118\n",
      "13     siconc_lag_1  -60.930261         60.930261\n",
      "14     siconc_lag_2  -56.524503         56.524503\n",
      "1               t2m   47.063523         47.063523\n",
      "2               sst  -26.221294         26.221294\n",
      "15     siconc_lag_3  -22.131921         22.131921\n",
      "10        sst_lag_1  -18.254143         18.254143\n",
      "11        sst_lag_2  -15.351382         15.351382\n",
      "7         t2m_lag_1  -14.411427         14.411427\n",
      "8         t2m_lag_2  -11.615316         11.615316\n",
      "12        sst_lag_3  -11.503368         11.503368\n",
      "16             year   -0.997732          0.997732\n",
      "9         t2m_lag_3   -0.996228          0.996228\n",
      "4          tp_lag_1    0.000000          0.000000\n",
      "5          tp_lag_2   -0.000000          0.000000\n",
      "6          tp_lag_3    0.000000          0.000000\n"
     ]
    }
   ],
   "source": [
    "df = penguin_df\n",
    "prep(df)\n",
    "X, y, scaler, features, scaled_features = prep(df)\n",
    "use_ridge_lasso(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Average R^2 Score: 0.522\n",
      "Random Forest Average RMSE: 284.066\n",
      "            Feature  Importance\n",
      "2               sst    0.276126\n",
      "18  day_of_year_cos    0.240799\n",
      "3            siconc    0.065304\n",
      "17  day_of_year_sin    0.047503\n",
      "16             year    0.047169\n",
      "1               t2m    0.043628\n",
      "12        sst_lag_3    0.034521\n",
      "10        sst_lag_1    0.031790\n",
      "11        sst_lag_2    0.027775\n",
      "7         t2m_lag_1    0.027616\n",
      "5          tp_lag_2    0.024497\n",
      "0                tp    0.023963\n",
      "6          tp_lag_3    0.023302\n",
      "8         t2m_lag_2    0.022342\n",
      "4          tp_lag_1    0.016907\n",
      "9         t2m_lag_3    0.016176\n",
      "13     siconc_lag_1    0.011346\n",
      "14     siconc_lag_2    0.010771\n",
      "15     siconc_lag_3    0.008463\n"
     ]
    }
   ],
   "source": [
    "df = penguin_df\n",
    "prep(df)\n",
    "X, y, scaler, features, scaled_features = prep(df)\n",
    "use_random_forest(X, y, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Average R^2 Score: 0.504\n",
      "XGBoost Average RMSE: 286.420\n",
      "            Feature  Importance\n",
      "18  day_of_year_cos    0.413217\n",
      "2               sst    0.119455\n",
      "17  day_of_year_sin    0.068181\n",
      "16             year    0.067367\n",
      "3            siconc    0.045540\n",
      "5          tp_lag_2    0.030590\n",
      "7         t2m_lag_1    0.028579\n",
      "12        sst_lag_3    0.028546\n",
      "10        sst_lag_1    0.023605\n",
      "8         t2m_lag_2    0.021775\n",
      "1               t2m    0.021429\n",
      "6          tp_lag_3    0.020392\n",
      "9         t2m_lag_3    0.020153\n",
      "11        sst_lag_2    0.019508\n",
      "15     siconc_lag_3    0.018964\n",
      "13     siconc_lag_1    0.016810\n",
      "4          tp_lag_1    0.014222\n",
      "14     siconc_lag_2    0.011655\n",
      "0                tp    0.010012\n"
     ]
    }
   ],
   "source": [
    "df = penguin_df\n",
    "prep(df)\n",
    "X, y, scaler, features, scaled_features = prep(df)\n",
    "use_xgb(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for species as a whole:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adelie Penguin\n",
      "Ridge Average R^2 Score: -1.347\n",
      "Ridge Average RMSE: 227.959\n",
      "Lasso Average R^2 Score: -1.326\n",
      "Lasso Average RMSE: 227.121\n",
      "\n",
      "Lasso Coefficients Sorted by Importance:\n",
      "            Feature  Lasso Coef  Lasso Importance\n",
      "3            siconc  288.878716        288.878716\n",
      "17  day_of_year_sin  171.148487        171.148487\n",
      "2               sst  -95.883206         95.883206\n",
      "18  day_of_year_cos   91.475233         91.475233\n",
      "15     siconc_lag_3  -62.830180         62.830180\n",
      "12        sst_lag_3  -18.119210         18.119210\n",
      "1               t2m  -14.293169         14.293169\n",
      "7         t2m_lag_1    8.661194          8.661194\n",
      "14     siconc_lag_2   -6.364093          6.364093\n",
      "10        sst_lag_1   -6.242779          6.242779\n",
      "11        sst_lag_2   -6.220027          6.220027\n",
      "8         t2m_lag_2    5.704054          5.704054\n",
      "13     siconc_lag_1   -5.301437          5.301437\n",
      "16             year   -3.796648          3.796648\n",
      "9         t2m_lag_3    1.858452          1.858452\n",
      "6          tp_lag_3    0.000000          0.000000\n",
      "5          tp_lag_2    0.000000          0.000000\n",
      "4          tp_lag_1    0.000000          0.000000\n",
      "0                tp    0.000000          0.000000\n",
      "Chinstrap Penguin\n",
      "Ridge Average R^2 Score: -2.101\n",
      "Ridge Average RMSE: 451.323\n",
      "Lasso Average R^2 Score: -2.146\n",
      "Lasso Average RMSE: 451.337\n",
      "\n",
      "Lasso Coefficients Sorted by Importance:\n",
      "            Feature   Lasso Coef  Lasso Importance\n",
      "3            siconc -1147.582611       1147.582611\n",
      "18  day_of_year_cos -1003.458496       1003.458496\n",
      "13     siconc_lag_1  1002.544173       1002.544173\n",
      "17  day_of_year_sin  -730.659790        730.659790\n",
      "15     siconc_lag_3   308.462334        308.462334\n",
      "6          tp_lag_3   147.781471        147.781471\n",
      "10        sst_lag_1   139.623044        139.623044\n",
      "11        sst_lag_2  -103.558572        103.558572\n",
      "14     siconc_lag_2    99.456064         99.456064\n",
      "2               sst    41.485180         41.485180\n",
      "12        sst_lag_3   -33.689121         33.689121\n",
      "9         t2m_lag_3   -19.292980         19.292980\n",
      "1               t2m    18.859005         18.859005\n",
      "7         t2m_lag_1    15.765614         15.765614\n",
      "16             year    10.325377         10.325377\n",
      "8         t2m_lag_2    -1.633444          1.633444\n",
      "5          tp_lag_2     0.000000          0.000000\n",
      "4          tp_lag_1    -0.000000          0.000000\n",
      "0                tp     0.000000          0.000000\n",
      "Gentoo Penguin\n",
      "Ridge Average R^2 Score: -1.454\n",
      "Ridge Average RMSE: 22.573\n",
      "Lasso Average R^2 Score: -1.189\n",
      "Lasso Average RMSE: 22.358\n",
      "\n",
      "Lasso Coefficients Sorted by Importance:\n",
      "            Feature  Lasso Coef  Lasso Importance\n",
      "2               sst  -26.426994         26.426994\n",
      "18  day_of_year_cos  -23.817086         23.817086\n",
      "12        sst_lag_3   10.944243         10.944243\n",
      "1               t2m   -8.027288          8.027288\n",
      "17  day_of_year_sin   -7.539684          7.539684\n",
      "8         t2m_lag_2    3.118562          3.118562\n",
      "9         t2m_lag_3    2.206129          2.206129\n",
      "15     siconc_lag_3   -2.106107          2.106107\n",
      "10        sst_lag_1    2.068868          2.068868\n",
      "16             year   -1.510227          1.510227\n",
      "7         t2m_lag_1    1.441471          1.441471\n",
      "11        sst_lag_2    0.365258          0.365258\n",
      "6          tp_lag_3   -0.000000          0.000000\n",
      "5          tp_lag_2   -0.000000          0.000000\n",
      "4          tp_lag_1   -0.000000          0.000000\n",
      "13     siconc_lag_1    0.000000          0.000000\n",
      "14     siconc_lag_2   -0.000000          0.000000\n",
      "3            siconc    0.000000          0.000000\n",
      "0                tp    0.000000          0.000000\n"
     ]
    }
   ],
   "source": [
    "species = penguin_df['common_name'].unique()\n",
    "for specie in species:\n",
    "    print(specie)\n",
    "    df = penguin_df[(penguin_df['common_name'] == specie)]\n",
    "    prep(df)\n",
    "    X, y, scaler, features, scaled_features = prep(df)\n",
    "    use_ridge_lasso(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adelie Penguin\n",
      "Random Forest Average R^2 Score: 0.214\n",
      "Random Forest Average RMSE: 184.114\n",
      "            Feature  Importance\n",
      "2               sst    0.579680\n",
      "16             year    0.149810\n",
      "3            siconc    0.092810\n",
      "18  day_of_year_cos    0.067687\n",
      "17  day_of_year_sin    0.045445\n",
      "1               t2m    0.010566\n",
      "14     siconc_lag_2    0.007029\n",
      "0                tp    0.005449\n",
      "12        sst_lag_3    0.004410\n",
      "15     siconc_lag_3    0.004388\n",
      "11        sst_lag_2    0.004379\n",
      "13     siconc_lag_1    0.004140\n",
      "8         t2m_lag_2    0.004047\n",
      "7         t2m_lag_1    0.003726\n",
      "10        sst_lag_1    0.003662\n",
      "9         t2m_lag_3    0.003573\n",
      "4          tp_lag_1    0.003139\n",
      "5          tp_lag_2    0.003055\n",
      "6          tp_lag_3    0.003005\n",
      "Chinstrap Penguin\n",
      "Random Forest Average R^2 Score: 0.175\n",
      "Random Forest Average RMSE: 437.258\n",
      "            Feature  Importance\n",
      "18  day_of_year_cos    0.459080\n",
      "2               sst    0.078201\n",
      "10        sst_lag_1    0.078039\n",
      "17  day_of_year_sin    0.074733\n",
      "1               t2m    0.032765\n",
      "0                tp    0.031357\n",
      "16             year    0.030161\n",
      "3            siconc    0.026884\n",
      "11        sst_lag_2    0.026877\n",
      "7         t2m_lag_1    0.023076\n",
      "12        sst_lag_3    0.021216\n",
      "6          tp_lag_3    0.021000\n",
      "8         t2m_lag_2    0.020231\n",
      "5          tp_lag_2    0.019809\n",
      "4          tp_lag_1    0.018780\n",
      "9         t2m_lag_3    0.016790\n",
      "13     siconc_lag_1    0.008101\n",
      "15     siconc_lag_3    0.007667\n",
      "14     siconc_lag_2    0.005232\n",
      "Gentoo Penguin\n",
      "Random Forest Average R^2 Score: -7.436\n",
      "Random Forest Average RMSE: 22.373\n",
      "            Feature  Importance\n",
      "2               sst    0.756395\n",
      "15     siconc_lag_3    0.036315\n",
      "14     siconc_lag_2    0.032134\n",
      "3            siconc    0.027010\n",
      "1               t2m    0.020550\n",
      "18  day_of_year_cos    0.013986\n",
      "8         t2m_lag_2    0.012015\n",
      "17  day_of_year_sin    0.011521\n",
      "9         t2m_lag_3    0.011496\n",
      "0                tp    0.010019\n",
      "11        sst_lag_2    0.009309\n",
      "5          tp_lag_2    0.009219\n",
      "10        sst_lag_1    0.008270\n",
      "13     siconc_lag_1    0.007930\n",
      "4          tp_lag_1    0.007847\n",
      "12        sst_lag_3    0.007786\n",
      "7         t2m_lag_1    0.006410\n",
      "6          tp_lag_3    0.006296\n",
      "16             year    0.005493\n"
     ]
    }
   ],
   "source": [
    "species = penguin_df['common_name'].unique()\n",
    "for specie in species:\n",
    "    print(specie)\n",
    "    df = penguin_df[(penguin_df['common_name'] == specie)]\n",
    "    prep(df)\n",
    "    X, y, scaler, features, scaled_features = prep(df)\n",
    "    use_random_forest(X, y, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = penguin_df['common_name'].unique()\n",
    "for specie in species:\n",
    "    print(specie)\n",
    "    df = penguin_df[(penguin_df['common_name'] == specie)]\n",
    "    prep(df)\n",
    "    X, y, scaler, features, scaled_features = prep(df)\n",
    "    use_xgb(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different colonies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the sufficient pairs and apply the ridge and lasso regression\n",
    "for pair in sufficient_pairs:\n",
    "    print(pair['specie'])\n",
    "    for colony in pair['colonies']:\n",
    "        print(colony)\n",
    "        df = penguin_df[(penguin_df['common_name'] == pair['specie']) & (penguin_df['colony_name'] == colony)]\n",
    "        prep(df)\n",
    "        X, y, scaler, features, scaled_features = prep(df)\n",
    "        use_ridge_lasso(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in sufficient_pairs:\n",
    "    print(pair['specie'])\n",
    "    for colony in pair['colonies']:\n",
    "        print(colony)\n",
    "        df = penguin_df[(penguin_df['common_name'] == pair['specie']) & (penguin_df['colony_name'] == colony)]\n",
    "        prep(df)\n",
    "        X, y, scaler, features, scaled_features = prep(df)\n",
    "        use_random_forest(X, y, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in sufficient_pairs:\n",
    "    print(pair['specie'])\n",
    "    for colony in pair['colonies']:\n",
    "        print(colony)\n",
    "        df = penguin_df[(penguin_df['common_name'] == pair['specie']) & (penguin_df['colony_name'] == colony)]\n",
    "        prep(df)\n",
    "        X, y, scaler, features, scaled_features = prep(df)\n",
    "        use_xgb(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
